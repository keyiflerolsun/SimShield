#!/usr/bin/env python3
# Bu araÃ§ @keyiflerolsun tarafÄ±ndan | CodeNight iÃ§in yazÄ±lmÄ±ÅŸtÄ±r.

"""
IoT SIM Filosu iÃ§in Ã¶rnek verileri JSON dosyalarÄ±ndan okuyarak MongoDB'ye yÃ¼kler
Sadece veri yÃ¼kleme iÅŸlemi yapar, anomali analizi arayÃ¼z Ã¼zerinden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
"""

import asyncio
import os
import json
from pathlib import Path
from datetime import datetime, timedelta
from motor.motor_asyncio import AsyncIOMotorClient
import random
import logging
from Settings import AYAR

# Logging yapÄ±landÄ±rmasÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# JSON dosyalarÄ±nÄ±n bulunduÄŸu dizin
SAMPLE_DATA_DIR = Path(__file__).parent / "sample_datas"

def load_json_file(filename):
    """JSON dosyasÄ±nÄ± yÃ¼kler"""
    file_path = SAMPLE_DATA_DIR / filename
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            logger.info(f"âœ… {filename} yÃ¼klendi ({len(data) if isinstance(data, list) else 'object'} kayÄ±t)")
            return data
    except FileNotFoundError:
        logger.error(f"âŒ Dosya bulunamadÄ±: {file_path}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSON parse hatasÄ± {filename}: {e}")
        raise
    except Exception as e:
        logger.error(f"âŒ Dosya okuma hatasÄ± {filename}: {e}")
        raise

async def wait_for_mongodb(max_retries=30, retry_interval=2):
    """MongoDB'nin hazÄ±r olmasÄ±nÄ± bekler"""
    retries = 0
    while retries < max_retries:
        try:
            mongodb_uri = os.environ.get('MONGODB_URI', AYAR["DATABASE"]["MONGODB"]["URI"])
            client = AsyncIOMotorClient(mongodb_uri)
            await client.admin.command('ping')
            logger.info("âœ… MongoDB baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
            client.close()
            return True
        except Exception as e:
            retries += 1
            logger.warning(f"â³ MongoDB bekleniyor... ({retries}/{max_retries}) - Hata: {e}")
            await asyncio.sleep(retry_interval)
    
    logger.error("âŒ MongoDB baÄŸlantÄ±sÄ± kurulamadÄ±!")
    return False

async def wait_for_redis(max_retries=30, retry_interval=2):
    """Redis'in hazÄ±r olmasÄ±nÄ± bekler"""
    retries = 0
    while retries < max_retries:
        try:
            import redis.asyncio as redis
            redis_host = os.environ.get('REDIS_HOST', AYAR["DATABASE"]["REDIS"]["HOST"])
            redis_port = int(os.environ.get('REDIS_PORT', AYAR["DATABASE"]["REDIS"]["PORT"]))
            
            redis_client = redis.Redis(host=redis_host, port=redis_port, db=0)
            await redis_client.ping()
            logger.info("âœ… Redis baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!")
            await redis_client.aclose()
            return True
        except Exception as e:
            retries += 1
            logger.warning(f"â³ Redis bekleniyor... ({retries}/{max_retries}) - Hata: {e}")
            await asyncio.sleep(retry_interval)
    
    logger.error("âŒ Redis baÄŸlantÄ±sÄ± kurulamadÄ±!")
    return False

def prepare_actions_log_data():
    """Eylem loglarÄ± verilerini hazÄ±rlar (tarih hesaplamalarÄ± ile)"""
    actions_data = load_json_file("actions_log.json")
    
    for action in actions_data:
        if "days_ago" in action:
            action["created_at"] = datetime.now() - timedelta(days=action["days_ago"])
            del action["days_ago"]
        elif "hours_ago" in action:
            action["created_at"] = datetime.now() - timedelta(hours=action["hours_ago"])
            del action["hours_ago"]
        else:
            action["created_at"] = datetime.now()
    
    return actions_data

async def generate_usage_data():
    """30 gÃ¼nlÃ¼k kullanÄ±m verisi oluÅŸturur - Normal kullanÄ±m + Ã§eÅŸitli anomali senaryolarÄ± ile"""
    usage_data = []
    base_date = datetime.now() - timedelta(days=30)
    
    # JSON dosyalarÄ±ndan verileri yÃ¼kle
    sims_data = load_json_file("sims.json")
    device_profiles_data = load_json_file("device_profiles.json")
    
    # Anomali senaryolarÄ± iÃ§in Ã¶zel SIM'ler - Ã‡eÅŸitlilik ve farklÄ± risk seviyeleri
    anomaly_scenarios = {
        # YÃœKSEK RÄ°SKLÄ° ANOMALILER (Risk: 80-100)
        "2001": {"type": "critical_usage_spike", "day": 25, "intensity": "extreme"},     # Kritik ani kullanÄ±m artÄ±ÅŸÄ±
        "2002": {"type": "massive_data_drain", "day": 20, "intensity": "extreme"},      # Masif veri tÃ¼ketimi
        "2003": {"type": "security_breach", "day": 22, "intensity": "extreme"},         # GÃ¼venlik ihlali ÅŸÃ¼phesi
        
        # ORTA RÄ°SKLÄ° ANOMALILER (Risk: 40-70)
        "2004": {"type": "sustained_drain", "day": 18, "intensity": "medium"},          # SÃ¼rekli yÃ¼ksek kullanÄ±m
        "2005": {"type": "pattern_change", "day": 15, "intensity": "medium"},           # KullanÄ±m kalÄ±bÄ± deÄŸiÅŸikliÄŸi
        "2006": {"type": "unexpected_roaming", "day": 12, "intensity": "medium"},       # Beklenmeyen roaming
        "2007": {"type": "device_malfunction", "day": 10, "intensity": "medium"},       # Cihaz arÄ±zasÄ± ÅŸÃ¼phesi
        "2008": {"type": "location_jump", "day": 8, "intensity": "medium"},             # Anormal lokasyon deÄŸiÅŸimi
        
        # DÃœÅÃœK RÄ°SKLÄ° ANOMALILER (Risk: 20-40)
        "2009": {"type": "mild_inactivity", "day": 5, "intensity": "low"},              # Hafif inaktivite
        "2010": {"type": "minor_spike", "day": 14, "intensity": "low"},                 # KÃ¼Ã§Ã¼k kullanÄ±m artÄ±ÅŸÄ±
        "2011": {"type": "cost_anomaly", "day": 16, "intensity": "low"},                # Maliyet anomalisi
        "2012": {"type": "gradual_increase", "day": 19, "intensity": "low"},            # Kademeli artÄ±ÅŸ
        
        # Ã‡OK DÃœÅÃœK RÄ°SKLÄ° (Risk: 10-20)
        "2013": {"type": "minor_variation", "day": 21, "intensity": "minimal"},         # KÃ¼Ã§Ã¼k varyasyon
        "2014": {"type": "weekend_anomaly", "day": 13, "intensity": "minimal"},         # Hafta sonu anomalisi
        
        # KARMA ANOMALILER (Birden fazla anomali tÃ¼rÃ¼)
        "2015": {"type": "multi_anomaly", "day": 7, "intensity": "high"},               # Karma anomali
        "2016": {"type": "progressive_drain", "day": 11, "intensity": "medium"}         # Kademeli veri tÃ¼ketimi
    }
    
    for sim in sims_data:
        sim_id = sim["sim_id"]
        device_type = sim["device_type"]
        
        # Cihaz profilini bul
        profile = next((p for p in device_profiles_data if p["device_type"] == device_type), None)
        if not profile:
            logger.warning(f"âš ï¸ {device_type} iÃ§in profil bulunamadÄ±, varsayÄ±lan deÄŸerler kullanÄ±lÄ±yor")
            min_mb = 1
            max_mb = 10
        else:
            min_mb = profile["expected_daily_mb_min"]
            max_mb = profile["expected_daily_mb_max"]
        
        # Bu SIM iÃ§in anomali senaryosu var mÄ±?
        anomaly_scenario = anomaly_scenarios.get(sim_id)
        
        for day in range(30):
            current_date = base_date + timedelta(days=day)
            
            # Normal kullanÄ±m (biraz varyasyon ekle)
            base_usage = random.uniform(min_mb, max_mb)
            
            # HaftalÄ±k pattern ekle (hafta sonu daha az kullanÄ±m)
            if current_date.weekday() >= 5:  # Hafta sonu
                base_usage *= 0.7
            
            # GÃ¼nlÃ¼k saatlik pattern ekle (gÃ¼ndÃ¼z daha aktif)
            hour_factor = 1.0
            current_hour = random.randint(0, 23)  # Rastgele bir saat simÃ¼le et
            if 6 <= current_hour <= 22:  # GÃ¼ndÃ¼z saatleri
                hour_factor = 1.2
            else:  # Gece saatleri
                hour_factor = 0.6
            
            base_usage *= hour_factor
            
            # Rastgele kÃ¼Ã§Ã¼k varyasyonlar ekle
            mb_used = base_usage * random.uniform(0.8, 1.2)
            
            # Anomali senaryolarÄ±nÄ± uygula
            if anomaly_scenario and day >= anomaly_scenario["day"]:
                anomaly_type = anomaly_scenario["type"]
                intensity = anomaly_scenario["intensity"]
                
                if anomaly_type == "critical_usage_spike":
                    # Kritik ani kullanÄ±m artÄ±ÅŸÄ± (Ã§ok yÃ¼ksek risk)
                    if day >= 25:
                        mb_used *= random.uniform(15, 25)  # 15-25x normal kullanÄ±m
                        
                elif anomaly_type == "massive_data_drain":
                    # Masif veri tÃ¼ketimi (sÃ¼rekli Ã§ok yÃ¼ksek)
                    if day >= 20:
                        mb_used *= random.uniform(10, 18)  # 10-18x normal kullanÄ±m
                        
                elif anomaly_type == "security_breach":
                    # GÃ¼venlik ihlali ÅŸÃ¼phesi (anormal pattern)
                    if day >= 22:
                        # Gece saatlerinde Ã§ok yÃ¼ksek kullanÄ±m
                        if current_hour < 6 or current_hour > 22:
                            mb_used *= random.uniform(12, 20)
                        else:
                            mb_used *= random.uniform(3, 6)
                            
                elif anomaly_type == "sustained_drain":
                    # SÃ¼rekli yÃ¼ksek kullanÄ±m (orta risk)
                    if day >= 18:
                        mb_used *= random.uniform(4, 7)  # 4-7x normal kullanÄ±m
                        
                elif anomaly_type == "pattern_change":
                    # KullanÄ±m kalÄ±bÄ± deÄŸiÅŸikliÄŸi (gece kullanÄ±mÄ±)
                    if day >= 15:
                        if current_hour < 6:  # Gece saatleri
                            mb_used *= random.uniform(5, 10)
                        elif 6 <= current_hour <= 12:  # Sabah saatleri
                            mb_used *= 0.2  # Ã‡ok dÃ¼ÅŸÃ¼k
                        else:
                            mb_used *= random.uniform(2, 4)
                            
                elif anomaly_type == "unexpected_roaming":
                    # Beklenmeyen roaming
                    if day >= 12:
                        mb_used *= random.uniform(2, 4)
                        
                elif anomaly_type == "device_malfunction":
                    # Cihaz arÄ±zasÄ± ÅŸÃ¼phesi (dÃ¼zensiz kullanÄ±m)
                    if day >= 10:
                        if random.random() < 0.3:  # %30 ihtimal Ã§ok yÃ¼ksek
                            mb_used *= random.uniform(8, 15)
                        elif random.random() < 0.3:  # %30 ihtimal Ã§ok dÃ¼ÅŸÃ¼k
                            mb_used *= 0.1
                        else:
                            mb_used *= random.uniform(1.5, 3)
                            
                elif anomaly_type == "location_jump":
                    # Anormal lokasyon deÄŸiÅŸimi (roaming ile birlikte)
                    if day >= 8:
                        mb_used *= random.uniform(3, 6)
                        
                elif anomaly_type == "mild_inactivity":
                    # Hafif inaktivite (dÃ¼ÅŸÃ¼k risk)
                    if day >= 5:
                        if random.random() < 0.7:  # %70 ihtimal inaktif
                            mb_used = 0
                        else:
                            mb_used *= 0.3
                            
                elif anomaly_type == "minor_spike":
                    # KÃ¼Ã§Ã¼k kullanÄ±m artÄ±ÅŸÄ±
                    if day >= 14:
                        mb_used *= random.uniform(2, 4)
                        
                elif anomaly_type == "cost_anomaly":
                    # Maliyet anomalisi (normal kullanÄ±m ama yÃ¼ksek maliyet)
                    if day >= 16:
                        mb_used *= random.uniform(1.5, 2.5)
                        
                elif anomaly_type == "gradual_increase":
                    # Kademeli artÄ±ÅŸ
                    if day >= 19:
                        days_since_start = day - 19
                        multiplier = 1 + (days_since_start * 0.5)  # Her gÃ¼n %50 artÄ±ÅŸ
                        mb_used *= multiplier
                        
                elif anomaly_type == "minor_variation":
                    # KÃ¼Ã§Ã¼k varyasyon (Ã§ok dÃ¼ÅŸÃ¼k risk)
                    if day >= 21:
                        mb_used *= random.uniform(1.3, 1.8)
                        
                elif anomaly_type == "weekend_anomaly":
                    # Hafta sonu anomalisi
                    if day >= 13 and current_date.weekday() >= 5:  # Hafta sonu
                        mb_used *= random.uniform(3, 6)
                        
                elif anomaly_type == "multi_anomaly":
                    # Karma anomali (birden fazla problem)
                    if day >= 7:
                        # Hem yÃ¼ksek kullanÄ±m hem de pattern deÄŸiÅŸikliÄŸi
                        if current_hour < 6:  # Gece
                            mb_used *= random.uniform(8, 15)
                        else:
                            mb_used *= random.uniform(4, 8)
                            
                elif anomaly_type == "progressive_drain":
                    # Kademeli veri tÃ¼ketimi artÄ±ÅŸÄ±
                    if day >= 11:
                        days_since_start = day - 11
                        multiplier = 2 + (days_since_start * 0.3)  # Kademeli artÄ±ÅŸ
                        mb_used *= multiplier
            
            # Roaming kullanÄ±mÄ±
            roaming_mb = 0
            if anomaly_scenario and day >= anomaly_scenario["day"]:
                anomaly_type = anomaly_scenario["type"]
                
                if anomaly_type == "unexpected_roaming":
                    # Beklenmeyen roaming - yoÄŸun roaming kullanÄ±mÄ±
                    roaming_mb = random.uniform(80, 200)  # Ã‡ok yÃ¼ksek roaming
                    
                elif anomaly_type == "location_jump":
                    # Lokasyon deÄŸiÅŸimi - anormal roaming pattern
                    roaming_mb = random.uniform(100, 300)  # Ekstrem roaming
                    
                elif anomaly_type == "security_breach":
                    # GÃ¼venlik ihlali - ÅŸÃ¼pheli roaming
                    roaming_mb = random.uniform(50, 150)
                    
                elif anomaly_type == "multi_anomaly":
                    # Karma anomali - roaming da dahil
                    roaming_mb = random.uniform(60, 180)
                    
            elif device_type == "Tracker" and random.random() < 0.1:  # Normal roaming
                roaming_mb = random.uniform(5, 20)
            
            usage_entry = {
                "sim_id": sim_id,
                "timestamp": current_date,
                "mb_used": round(max(0, mb_used), 2),
                "roaming_mb": round(max(0, roaming_mb), 2),
                "cost": 0.0,  # Maliyet hesaplamasÄ± iÃ§in placeholder
                "overage": 0.0
            }
            
            usage_data.append(usage_entry)
    
    logger.info(f"ğŸ“Š {len(usage_data)} kullanÄ±m kaydÄ± oluÅŸturuldu (16 farklÄ± anomali senaryosu dahil - Risk seviyeleri: DÃ¼ÅŸÃ¼k/Orta/YÃ¼ksek/Kritik)")
    return usage_data

async def load_sample_data():
    """Ã–rnek verileri JSON dosyalarÄ±ndan okuyarak MongoDB'ye yÃ¼kler"""
    try:
        logger.info("ğŸš€ SimShield Sample Data Loader baÅŸlatÄ±lÄ±yor...")
        logger.info("ğŸ”„ JSON dosyalarÄ± kontrol ediliyor...")
        
        # Sample data dizininin varlÄ±ÄŸÄ±nÄ± kontrol et
        if not SAMPLE_DATA_DIR.exists():
            raise FileNotFoundError(f"Sample data dizini bulunamadÄ±: {SAMPLE_DATA_DIR}")
        
        logger.info(f"ğŸ“ Sample data dizini: {SAMPLE_DATA_DIR.absolute()}")
        
        # JSON dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
        required_files = [
            "customers.json", "sims.json", "iot_plans.json", 
            "device_profiles.json", "add_on_packs.json", "actions_log.json"
        ]
        
        for file in required_files:
            if not (SAMPLE_DATA_DIR / file).exists():
                raise FileNotFoundError(f"Gerekli JSON dosyasÄ± bulunamadÄ±: {file}")
        
        # Servislerin hazÄ±r olmasÄ±nÄ± bekle
        logger.info("ğŸ”„ VeritabanÄ± servislerinin hazÄ±r olmasÄ± bekleniyor...")
        
        if not await wait_for_mongodb():
            raise Exception("MongoDB baÄŸlantÄ±sÄ± kurulamadÄ±")
        
        if not await wait_for_redis():
            raise Exception("Redis baÄŸlantÄ±sÄ± kurulamadÄ±")
        
        # MongoDB baÄŸlantÄ±sÄ±
        mongodb_uri = os.environ.get('MONGODB_URI', AYAR["DATABASE"]["MONGODB"]["URI"])
        client = AsyncIOMotorClient(mongodb_uri)
        db = client[AYAR["DATABASE"]["MONGODB"]["NAME"]]
        
        logger.info("ğŸ“‚ JSON dosyalarÄ±ndan Ã¶rnek veriler yÃ¼kleniyor...")
        
        # JSON dosyalarÄ±nÄ± yÃ¼kle
        customers_data = load_json_file("customers.json")
        sims_data = load_json_file("sims.json")
        iot_plans_data = load_json_file("iot_plans.json")
        device_profiles_data = load_json_file("device_profiles.json")
        add_on_packs_data = load_json_file("add_on_packs.json")
        actions_log_data = prepare_actions_log_data()
        
        # MÃ¼ÅŸteriler
        logger.info("ğŸ‘¥ MÃ¼ÅŸteri verileri yÃ¼kleniyor...")
        customers_collection = db["customers"]
        await customers_collection.delete_many({})
        await customers_collection.insert_many(customers_data)
        logger.info(f"âœ… {len(customers_data)} mÃ¼ÅŸteri yÃ¼klendi")
        
        # SIM kartlarÄ±
        logger.info("ğŸ“± SIM kartlarÄ± yÃ¼kleniyor...")
        sims_collection = db["sims"]
        await sims_collection.delete_many({})
        
        for sim in sims_data:
            # Temel alanlarÄ± ekle
            sim["risk_score"] = 0
            sim["risk_level"] = "green"
            sim["anomaly_count"] = 0
            sim["anomalies"] = []
            sim["last_analysis"] = None
            sim["last_seen_at"] = datetime.now() - timedelta(hours=random.randint(1, 24))
            sim["created_at"] = datetime.now() - timedelta(days=random.randint(30, 365))
            
            # JSON aÃ§Ä±klama notlarÄ±nÄ± temizle
            if "_note" in sim:
                del sim["_note"]
        
        await sims_collection.insert_many(sims_data)
        logger.info(f"âœ… {len(sims_data)} SIM kartÄ± yÃ¼klendi (Risk skorlarÄ± sÄ±fÄ±r - Analiz iÃ§in hazÄ±r)")
        
        # IoT PlanlarÄ±
        logger.info("ğŸ“‹ IoT planlarÄ± yÃ¼kleniyor...")
        plans_collection = db["iot_plans"]
        await plans_collection.delete_many({})
        await plans_collection.insert_many(iot_plans_data)
        logger.info(f"âœ… {len(iot_plans_data)} IoT planÄ± yÃ¼klendi")
        
        # Cihaz Profilleri
        logger.info("ğŸ”§ Cihaz profilleri yÃ¼kleniyor...")
        profiles_collection = db["device_profiles"]
        await profiles_collection.delete_many({})
        await profiles_collection.insert_many(device_profiles_data)
        logger.info(f"âœ… {len(device_profiles_data)} cihaz profili yÃ¼klendi")
        
        # Ek Paketler
        logger.info("ğŸ“¦ Ek paketler yÃ¼kleniyor...")
        addons_collection = db["add_on_packs"]
        await addons_collection.delete_many({})
        await addons_collection.insert_many(add_on_packs_data)
        logger.info(f"âœ… {len(add_on_packs_data)} ek paket yÃ¼klendi")
        
        # Eylem LoglarÄ±
        logger.info("ğŸ“ Eylem loglarÄ± yÃ¼kleniyor...")
        actions_collection = db["actions_log"]
        await actions_collection.delete_many({})
        await actions_collection.insert_many(actions_log_data)
        logger.info(f"âœ… {len(actions_log_data)} eylem logu yÃ¼klendi")
        
        # Normal KullanÄ±m Verileri
        logger.info("ğŸ“Š 30 gÃ¼nlÃ¼k normal kullanÄ±m verileri oluÅŸturuluyor...")
        usage_collection = db["usage"]
        await usage_collection.delete_many({})
        usage_data = await generate_usage_data()
        
        # BÃ¼yÃ¼k veri setini chunk'lara bÃ¶lerek insert et
        chunk_size = 100
        for i in range(0, len(usage_data), chunk_size):
            chunk = usage_data[i:i + chunk_size]
            await usage_collection.insert_many(chunk)
        
        logger.info(f"âœ… {len(usage_data)} normal kullanÄ±m kaydÄ± yÃ¼klendi")
        
        # VeritabanÄ± indekslerini oluÅŸtur
        logger.info("ğŸ” VeritabanÄ± indeksleri oluÅŸturuluyor...")
        
        await sims_collection.create_index("sim_id", unique=True)
        await sims_collection.create_index("customer_id")
        await sims_collection.create_index("status")
        await sims_collection.create_index("risk_score")
        await sims_collection.create_index("device_type")
        
        await usage_collection.create_index([("sim_id", 1), ("timestamp", -1)])
        await usage_collection.create_index("timestamp")
        await usage_collection.create_index("sim_id")
        
        await customers_collection.create_index("customer_id", unique=True)
        await plans_collection.create_index("plan_id", unique=True)
        await actions_collection.create_index("sim_id")
        await actions_collection.create_index("created_at")
        
        logger.info("âœ… VeritabanÄ± indeksleri oluÅŸturuldu")
        
        # Redis cache'i baÅŸlat
        logger.info("ğŸš€ Redis cache baÅŸlatÄ±lÄ±yor...")
        try:
            import redis.asyncio as redis
            redis_host = os.environ.get('REDIS_HOST', AYAR["DATABASE"]["REDIS"]["HOST"])
            redis_port = int(os.environ.get('REDIS_PORT', AYAR["DATABASE"]["REDIS"]["PORT"]))
            
            redis_client = redis.Redis(host=redis_host, port=redis_port, db=0)
            
            # Cache'e temel verileri yÃ¼kle
            await redis_client.set("data_loaded", "true", ex=3600)  # 1 saat
            await redis_client.set("last_data_load", datetime.now().isoformat(), ex=3600)
            await redis_client.set("total_sims", str(len(sims_data)), ex=3600)
            await redis_client.set("total_customers", str(len(customers_data)), ex=3600)
            
            logger.info("âœ… Redis cache baÅŸlatÄ±ldÄ±")
            await redis_client.aclose()
            
        except Exception as e:
            logger.warning(f"âš ï¸ Redis cache baÅŸlatÄ±lamadÄ±: {e}")
        
        # BaÅŸarÄ± mesajlarÄ±
        logger.info("\nğŸ‰ TÃ¼m Ã¶rnek veriler JSON dosyalarÄ±ndan baÅŸarÄ±yla yÃ¼klendi!")
        logger.info("=" * 60)
        logger.info("ğŸ“Š Dashboard URL: http://127.0.0.1:3310")
        logger.info("ğŸ”— API Docs: http://127.0.0.1:3310/api/v1/docs")
        logger.info("ğŸ“ˆ Analytics: http://127.0.0.1:3310/api/v1/fleet")
        logger.info("ğŸ” Anomali analizi arayÃ¼zden 'TÃ¼m SIM'leri Analiz Et' butonu ile Ã§alÄ±ÅŸtÄ±rÄ±labilir")
        logger.info("=" * 60)
        
        # Veri Ã¶zeti
        logger.info(f"\nğŸ“‹ YÃ¼klenen Veri Ã–zeti:")
        logger.info(f"   â€¢ {len(customers_data)} MÃ¼ÅŸteri ({len(set(c['sector'] for c in customers_data))} farklÄ± sektÃ¶r)")
        logger.info(f"   â€¢ {len(sims_data)} SIM KartÄ± (Risk skorlarÄ± sÄ±fÄ±r - Analiz iÃ§in hazÄ±r)")
        logger.info(f"   â€¢ {len(iot_plans_data)} IoT PlanÄ±")
        logger.info(f"   â€¢ {len(usage_data)} Normal KullanÄ±m KaydÄ± (30 gÃ¼n)")
        logger.info(f"   â€¢ {len(actions_log_data)} Eylem Logu")
        logger.info(f"   â€¢ {len(device_profiles_data)} Cihaz Profili")
        logger.info(f"   â€¢ {len(add_on_packs_data)} Ek Paket")
        
        # JSON dosya listesi
        logger.info(f"\nğŸ“ KullanÄ±lan JSON DosyalarÄ±:")
        for json_file in SAMPLE_DATA_DIR.glob("*.json"):
            file_size = json_file.stat().st_size
            logger.info(f"   â€¢ {json_file.name} ({file_size} bytes)")
        
        # Ä°statistikler
        device_types = {}
        cities = {}
        for sim in sims_data:
            device_type = sim.get("device_type", "Unknown")
            city = sim.get("city", "Unknown")
            device_types[device_type] = device_types.get(device_type, 0) + 1
            cities[city] = cities.get(city, 0) + 1
        
        logger.info(f"\nğŸ“Š SIM KartÄ± DaÄŸÄ±lÄ±mÄ±:")
        logger.info(f"   Cihaz Tipleri: {dict(sorted(device_types.items()))}")
        logger.info(f"   Åehirler: {dict(sorted(cities.items()))}")
        
        logger.info(f"\nğŸš€ Sistem hazÄ±r! Anomali analizi iÃ§in arayÃ¼zÃ¼ kullanÄ±n.")
        
        client.close()
        
    except Exception as e:
        logger.error(f"âŒ Veri yÃ¼kleme hatasÄ±: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(load_sample_data())